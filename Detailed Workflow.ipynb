{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5809e0c2",
   "metadata": {},
   "source": [
    "# Flight Price Prediction - Final Workflow\n",
    "\n",
    "This notebook demonstrates the complete pipeline for predicting flight prices using machine learning.\n",
    "\n",
    "## Dataset\n",
    "The dataset contains flight booking information from Indian cities with features like airline, source, destination, departure/arrival times, duration, and price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79a79e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a561c1",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"Data_Train.xlsx\")\n",
    "print(f\"Dataset shape: {df_train.shape}\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6acdde",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aed4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_train = df_train.dropna()\n",
    "print(f\"\\nShape after removing nulls: {df_train.shape}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df_train.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_train = df_train.drop_duplicates()\n",
    "print(f\"Shape after removing duplicates: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copy\n",
    "data = df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aae9f1",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "### 4.1 Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a446d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features\n",
    "data[\"Date_of_Journey\"] = pd.to_datetime(data[\"Date_of_Journey\"], format=\"%d/%m/%Y\")\n",
    "data[\"Journey_day\"] = data[\"Date_of_Journey\"].dt.day\n",
    "data[\"Journey_month\"] = data[\"Date_of_Journey\"].dt.month\n",
    "data[\"Journey_year\"] = data[\"Date_of_Journey\"].dt.year\n",
    "\n",
    "print(\"Date features created:\")\n",
    "data[[\"Date_of_Journey\", \"Journey_day\", \"Journey_month\", \"Journey_year\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd00d7",
   "metadata": {},
   "source": [
    "### 4.2 Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0930c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "data[\"Arrival_hour\"] = pd.to_datetime(data[\"Arrival_Time\"]).dt.hour\n",
    "data[\"Arrival_min\"] = pd.to_datetime(data[\"Arrival_Time\"]).dt.minute\n",
    "data[\"Departure_hour\"] = pd.to_datetime(data[\"Dep_Time\"]).dt.hour\n",
    "data[\"Departure_min\"] = pd.to_datetime(data[\"Dep_Time\"]).dt.minute\n",
    "\n",
    "print(\"Time features created:\")\n",
    "data[[\"Dep_Time\", \"Departure_hour\", \"Departure_min\", \"Arrival_Time\", \"Arrival_hour\", \"Arrival_min\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc366b",
   "metadata": {},
   "source": [
    "### 4.3 Duration Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process duration\n",
    "def preprocess_duration(x):\n",
    "    if \"h\" not in x:\n",
    "        x = \"0h \" + x\n",
    "    elif \"m\" not in x:\n",
    "        x = x + \" 0m\"\n",
    "    return x\n",
    "\n",
    "data[\"Duration\"] = data[\"Duration\"].apply(preprocess_duration)\n",
    "data[\"Duration_hour\"] = pd.to_timedelta(data[\"Duration\"]).dt.components.hours\n",
    "data[\"Duration_minutes\"] = pd.to_timedelta(data[\"Duration\"]).dt.components.minutes\n",
    "data[\"Total_min\"] = data[\"Duration_hour\"] * 60 + data[\"Duration_minutes\"]\n",
    "\n",
    "print(\"Duration features created:\")\n",
    "data[[\"Duration\", \"Duration_hour\", \"Duration_minutes\", \"Total_min\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046975c",
   "metadata": {},
   "source": [
    "### 4.4 Price Conversion to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert price to USD\n",
    "def convert_to_usd(x):\n",
    "    return int(x * 0.0142)\n",
    "\n",
    "data[\"Price_USD\"] = data[\"Price\"].apply(convert_to_usd)\n",
    "print(f\"Price range in USD: ${data['Price_USD'].min()} - ${data['Price_USD'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dacb4d",
   "metadata": {},
   "source": [
    "### 4.5 Process Total Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number of stops\n",
    "def extract_stops(x):\n",
    "    match = re.search(r'\\d+', str(x))\n",
    "    return int(match.group()) if match else 0\n",
    "\n",
    "data[\"Total_Stops\"] = data[\"Total_Stops\"].apply(extract_stops)\n",
    "print(\"Stops distribution:\")\n",
    "print(data[\"Total_Stops\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883497bc",
   "metadata": {},
   "source": [
    "### 4.6 Clean Destination Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize destination names\n",
    "data[\"Destination\"].replace(\"New Delhi\", \"Delhi\", inplace=True)\n",
    "print(\"Unique destinations:\")\n",
    "print(data[\"Destination\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3b9d6",
   "metadata": {},
   "source": [
    "### 4.7 Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ed920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we don't need\n",
    "cols_to_drop = [\"Dep_Time\", \"Arrival_Time\", \"Duration\", \"Date_of_Journey\", \n",
    "                \"Price\", \"Additional_Info\", \"Route\", \"Journey_year\", \n",
    "                \"Duration_hour\", \"Duration_minutes\"]\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "print(f\"Remaining columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b75507",
   "metadata": {},
   "source": [
    "## 5. Encoding Categorical Variables\n",
    "\n",
    "### 5.1 One-Hot Encode Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode source city\n",
    "source_dummies = pd.get_dummies(data[\"Source\"], prefix=\"Source\").astype(int)\n",
    "data = pd.concat([data, source_dummies], axis=1)\n",
    "data.drop(\"Source\", axis=1, inplace=True)\n",
    "print(f\"Source columns created: {list(source_dummies.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad93898",
   "metadata": {},
   "source": [
    "### 5.2 Label Encode Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode airlines by average price\n",
    "airlines = data.groupby([\"Airline\"])[\"Price_USD\"].mean().sort_values().index\n",
    "airlines_dict = dict(zip(airlines, range(len(airlines))))\n",
    "data[\"Airline\"] = data[\"Airline\"].map(airlines_dict)\n",
    "print(\"Airline encoding:\")\n",
    "for airline, code in airlines_dict.items():\n",
    "    print(f\"  {airline}: {code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0215",
   "metadata": {},
   "source": [
    "### 5.3 Label Encode Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a754cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode destinations by average price\n",
    "destinations = data.groupby([\"Destination\"])[\"Price_USD\"].mean().sort_values().index\n",
    "dest_dict = dict(zip(destinations, range(len(destinations))))\n",
    "data[\"Destination\"] = data[\"Destination\"].map(dest_dict)\n",
    "print(\"Destination encoding:\")\n",
    "for dest, code in dest_dict.items():\n",
    "    print(f\"  {dest}: {code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe2f40",
   "metadata": {},
   "source": [
    "### 5.4 Remove Duplicate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns if any\n",
    "data = data.loc[:, ~data.columns.duplicated()]\n",
    "print(f\"Final shape: {data.shape}\")\n",
    "print(f\"Final columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a22c92",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection and Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price distribution before outlier removal\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=data[\"Price_USD\"])\n",
    "plt.title(\"Price Distribution - Before Outlier Removal\")\n",
    "\n",
    "# Calculate IQR\n",
    "q1 = data[\"Price_USD\"].quantile(0.25)\n",
    "q3 = data[\"Price_USD\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "maximum = q3 + 1.5 * iqr\n",
    "minimum = q1 - 1.5 * iqr\n",
    "\n",
    "print(f\"IQR Method:\")\n",
    "print(f\"  Q1: ${q1:.2f}\")\n",
    "print(f\"  Q3: ${q3:.2f}\")\n",
    "print(f\"  IQR: ${iqr:.2f}\")\n",
    "print(f\"  Lower bound: ${minimum:.2f}\")\n",
    "print(f\"  Upper bound: ${maximum:.2f}\")\n",
    "\n",
    "# Count outliers\n",
    "outliers = len(data[(data[\"Price_USD\"] < minimum) | (data[\"Price_USD\"] > maximum)])\n",
    "print(f\"\\nOutliers found: {outliers} ({outliers/len(data)*100:.2f}%)\")\n",
    "\n",
    "# Remove outliers\n",
    "data = data[(data[\"Price_USD\"] >= minimum) & (data[\"Price_USD\"] <= maximum)]\n",
    "print(f\"Shape after removing outliers: {data.shape}\")\n",
    "\n",
    "# Visualize after\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=data[\"Price_USD\"])\n",
    "plt.title(\"Price Distribution - After Outlier Removal\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32277ec4",
   "metadata": {},
   "source": [
    "## 7. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = data.drop([\"Price_USD\"], axis=1)\n",
    "y = data[\"Price_USD\"]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eacce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef034d",
   "metadata": {},
   "source": [
    "## 8. Model Training and Evaluation\n",
    "\n",
    "### 8.1 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rfr_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rfr = rfr_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Regressor Performance:\")\n",
    "print(f\"  Training Score: {rfr_model.score(X_train, y_train):.4f}\")\n",
    "print(f\"  Testing Score (R²): {metrics.r2_score(y_test, y_pred_rfr):.4f}\")\n",
    "print(f\"  MAE: ${metrics.mean_absolute_error(y_test, y_pred_rfr):.2f}\")\n",
    "print(f\"  MSE: ${metrics.mean_squared_error(y_test, y_pred_rfr):.2f}\")\n",
    "print(f\"  RMSE: ${np.sqrt(metrics.mean_squared_error(y_test, y_pred_rfr)):.2f}\")\n",
    "print(f\"  MAPE: {metrics.mean_absolute_percentage_error(y_test, y_pred_rfr):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c987c1",
   "metadata": {},
   "source": [
    "### 8.2 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree\n",
    "dtr_model = DecisionTreeRegressor(random_state=42)\n",
    "dtr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dtr = dtr_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Decision Tree Regressor Performance:\")\n",
    "print(f\"  Training Score: {dtr_model.score(X_train, y_train):.4f}\")\n",
    "print(f\"  Testing Score (R²): {metrics.r2_score(y_test, y_pred_dtr):.4f}\")\n",
    "print(f\"  MAE: ${metrics.mean_absolute_error(y_test, y_pred_dtr):.2f}\")\n",
    "print(f\"  MSE: ${metrics.mean_squared_error(y_test, y_pred_dtr):.2f}\")\n",
    "print(f\"  RMSE: ${np.sqrt(metrics.mean_squared_error(y_test, y_pred_dtr)):.2f}\")\n",
    "print(f\"  MAPE: {metrics.mean_absolute_percentage_error(y_test, y_pred_dtr):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abc090",
   "metadata": {},
   "source": [
    "### 8.3 Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": rfr_model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance.head(10), x=\"Importance\", y=\"Feature\")\n",
    "plt.title(\"Top 10 Most Important Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8338a4",
   "metadata": {},
   "source": [
    "### 8.4 Prediction vs Actual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd07058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_rfr, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Price (USD)\")\n",
    "plt.ylabel(\"Predicted Price (USD)\")\n",
    "plt.title(\"Random Forest: Actual vs Predicted\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_dtr, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Price (USD)\")\n",
    "plt.ylabel(\"Predicted Price (USD)\")\n",
    "plt.title(\"Decision Tree: Actual vs Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d5bb66",
   "metadata": {},
   "source": [
    "## 9. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Random Forest model\n",
    "with open(\"rfr.pkl\", \"wb\") as file:\n",
    "    pickle.dump(rfr_model, file)\n",
    "print(\"Random Forest model saved as rfr.pkl\")\n",
    "\n",
    "# Save Decision Tree model\n",
    "with open(\"dtr.pkl\", \"wb\") as file:\n",
    "    pickle.dump(dtr_model, file)\n",
    "print(\"Decision Tree model saved as dtr.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef8116",
   "metadata": {},
   "source": [
    "## 10. Model Validation - Load and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7db604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model and verify\n",
    "with open(\"rfr.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Test loaded model\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "r2_loaded = metrics.r2_score(y_test, y_pred_loaded)\n",
    "\n",
    "print(f\"Loaded model R² score: {r2_loaded:.4f}\")\n",
    "print(\"Model successfully saved and loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0899c2b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline:\n",
    "\n",
    "1. **Data Loading**: Loaded flight booking data\n",
    "2. **Data Cleaning**: Handled missing values and duplicates\n",
    "3. **Feature Engineering**: \n",
    "   - Extracted date/time features\n",
    "   - Processed duration\n",
    "   - Converted price to USD\n",
    "   - Extracted number of stops\n",
    "4. **Encoding**: \n",
    "   - One-hot encoded source cities\n",
    "   - Label encoded airlines and destinations by price\n",
    "5. **Outlier Removal**: Used IQR method to remove price outliers\n",
    "6. **Model Training**: Trained Random Forest and Decision Tree models\n",
    "7. **Evaluation**: Compared model performance using multiple metrics\n",
    "8. **Model Persistence**: Saved models for deployment\n",
    "\n",
    "The models are ready to be used in a Flask web application for real-time flight price predictions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
